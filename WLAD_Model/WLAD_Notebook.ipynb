{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFkDMm10DPK7"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wrightky/ANUGA_DXWorkshop/blob/main/WLAD_Model/WLAD_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "#<div align=\"center\">**Wax Lake & Atchafalaya Delta Model**</div>\n",
        "##<div align=\"center\">ANUGA Tutorial</div>\n",
        "##<div align=\"center\">Kyle Wright</div>\n",
        "###<div align=\"center\">Delta-X Applications Workshop (May 5th, 2022)</div>\n",
        "\n",
        "## Information on this session:\n",
        "\n",
        "**Goal:** Introduce the basics of the hydrodynamic model for the Wax Lake & Atchafalaya Delta (WLAD) basin using ANUGA. This model solves the 2D shallow-water equations on an unstructured triangular grid. Note that the model structure has been slightly simplified for parts of this demonstration.\n",
        "\n",
        "**Software:** ANUGA, Python, Jupyter Notebooks, other packages\n",
        "\n",
        "**Installation:** None, this lab is run on the cloud in the Google `colaboratory` environment.\n",
        "\n",
        "**Details:** In this tutorial, we will build, run, and analyze our model of the actively-aggrading WLAD basin. This is one of the two Delta-X study sites, and we will be simulating the period that aligns with the Spring 2021 campaign. Different cell blocks will demonstate how one can build the model mesh, initialize the domain, setup the parameters of the model, and run the simulation. \n",
        "\n",
        "The regular version of this model is written as a collection of Python scripts that are run in parallel on a high-performance computing cluster (e.g. [TACC](https://www.tacc.utexas.edu/)). However, we have simplified the model here to allow it to run in this notebook on Google Colab, so that we can demonstrate the workflow of the model, which is identical to that in the true version. The raw codes for the current parallel implementation have been included in this repository along with this notebook, so feel free to glance through those as well. \n",
        "\n",
        "This notebook is written in Python 3, and has been designed to run in the Google `colaboratory` environment, which provides a Jupyter notebook environment running on a virtual machine on the cloud. Nothing needs to be installed locally, as it is entirely run on Google Drive. All you need is a Google account. All of these scripts are stored on GitHub.\n",
        "\n",
        "To start interacting with the notebook, make sure it is open in Colab (see `Open in Colab` link above). Once you're there, click `File` > `Save a Copy in Drive`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt-Ti7kdQX3C"
      },
      "source": [
        "## Setup Environment\n",
        "\n",
        "The first thing we have to do is set up our environment. In Python, this means downloading all the necessary functions we want to use, including ANUGA.\n",
        "\n",
        "Run the following cell to install the dependencies and some extra code for visualising on Colaboratory. The install should take less than a minute.\n",
        "\n",
        "*Pro-tip: To run each code block, you can simply type `shift` + `enter`*\n",
        "\n",
        "NOTE: Tutorial installation is based on the [2018 CSDMS Anuga Clinic](https://github.com/stoiver/anuga-clinic-2018), but updated to work in Python 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xdCgMgk7_ZcW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d07b5b6-078c-46ad-8773-dc3fe28b23f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ANUGA_DXWorkshop'...\n",
            "remote: Enumerating objects: 249, done.\u001b[K\n",
            "remote: Counting objects: 100% (249/249), done.\u001b[K\n",
            "remote: Compressing objects: 100% (229/229), done.\u001b[K\n",
            "remote: Total 249 (delta 22), reused 240 (delta 17), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (249/249), 2.24 MiB | 6.67 MiB/s, done.\n",
            "Resolving deltas: 100% (22/22), done.\n",
            "(1) Install pip packages\n",
            "(2) Install gdal\n",
            "(3) Install netcdf4\n",
            "(4) Download anuga_core github repository\n",
            "(5) Install anuga\n",
            "(6) Ready to go\n"
          ]
        }
      ],
      "source": [
        "# Here we download/install all the files we need behind the scenes\n",
        "try:\n",
        "    import os\n",
        "    os.chdir('/content')\n",
        "    # Grab workbook files into colab directory\n",
        "    !git clone https://github.com/wrightky/ANUGA_DXWorkshop.git\n",
        "    # Install everything using some bash scripts\n",
        "    !/bin/bash /content/ANUGA_DXWorkshop/anuga_tools/install_anuga_colab.sh\n",
        "    !python /content/ANUGA_DXWorkshop/anuga_tools/install.py > /dev/null 2>&1 \n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Deal with some directory stuff\n",
        "if not 'workbookDir' in globals():\n",
        "    workbookDir = os.getcwd()\n",
        "import sys\n",
        "sys.path.append(os.path.join(workbookDir,\"ANUGA_DXWorkshop\"))\n",
        "sys.path.append(os.path.join(workbookDir,\"anuga_core\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import packages\n",
        "\n",
        "Now that everything is installed, we can load the packages we want to use directly into this notebook. Most of these are very common packages, and each one contains a different group of functions that are useful for scientific applications. We access these functions by 'importing' the packages we need. See the comments below for a brief discription of what each of these packages are for."
      ],
      "metadata": {
        "id": "SUcbRbVRFYX2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VP3EdHMheBND"
      },
      "outputs": [],
      "source": [
        "import numpy as np # Array manipulation, most important Python package\n",
        "import matplotlib # Plotting/visualization\n",
        "import matplotlib.pyplot as plt # Convenient shorthand for the main plotting function\n",
        "matplotlib.use('Agg') # Settings\n",
        "%matplotlib inline\n",
        "from scipy.interpolate import interp1d # Simple linear interpolation\n",
        "import pandas as pd # Spreadsheets/excel data\n",
        "import os # Operating system, handles directories\n",
        "import glob # Also for files\n",
        "# from PIL import Image # For making output animations\n",
        "import anuga # The model itself\n",
        "from anuga.utilities import animate # Built-in plotting tool for the model\n",
        "from anuga import Inlet_operator # Explained later"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWcVleSleW-9"
      },
      "source": [
        "## Create ANUGA domain and mesh\n",
        "\n",
        "Now we can begin constructing our model domain. This means we need to create a mesh, add any initial and boundary conditions, and handle any settings.\n",
        "\n",
        "First, we need to specify our model geometry. In the following cell, we specify the coordinates of the boundary polygon for our model, and **instantiate the model domain and mesh** from that polygon. The internal mesh engine does almost all of the work for us here, we just need to feed it our **domain size**, desired **mesh resolution**, and any **interior polygons** we might want (if we have any). \n",
        "\n",
        "Interior polygons are one of the powerful features of ANUGA. We can have any number of regions inside our domain with their own mesh resolution. Is there an area you really care about and want to model in high-resolution? Easy. Is there an area you need to include but don't care a lot about, and can make very coarse to save computational time? Also easy. The main constraint is that the polygons defining the boundary of those regions can't overlap.\n",
        "\n",
        "For visualization, we will be making use of ANUGA's `animate.Domain_plotter` tool, which we initialize here and call repeatedly later.\n",
        "\n",
        "*Note: Always make sure units are in metric, ANUGA does not support customary units*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UP95gC9peQE3"
      },
      "outputs": [],
      "source": [
        "# ---------------Define Domain Boundary-----------------\n",
        "bounding_polygon = [[622338.0, 3339415.0], [623005.0, 3341128.0],\n",
        "                    [626983.0, 3340039.0], [626675.0, 3338530.0]]\n",
        "\n",
        "# Assign a name to the different kinds of boundaries, needed for BCs later\n",
        "boundary_tags={'sides': [0,1,3], 'downstream': [2]} # ID of segments, not points\n",
        "\n",
        "# ---------------Define Geo Reference-------------------\n",
        "geo_reference = anuga.Geo_reference(zone=14,\n",
        "                                    datum='wgs84',\n",
        "                                    projection='UTM',\n",
        "                                    false_easting=500000,\n",
        "                                    false_northing=0)\n",
        "\n",
        "# Mesh Resolution (max area of triangles in each given region)\n",
        "base_res = 625. # Ensures that all cells have less area than this max value\n",
        "\n",
        "# ---------------Generate domain and mesh---------------\n",
        "domain = anuga.create_domain_from_regions(bounding_polygon, boundary_tags,\n",
        "                                          maximum_triangle_area=base_res,\n",
        "                                          mesh_geo_reference=geo_reference,\n",
        "                                          mesh_filename='onion.msh')\n",
        "\n",
        "# Plot mesh\n",
        "fig = plt.figure(figsize=(5, 5), dpi=250, facecolor='w', edgecolor='k')\n",
        "dplotter = animate.Domain_plotter(domain)\n",
        "plt.triplot(dplotter.triang, linewidth=0.1);\n",
        "plt.axis('scaled')\n",
        "\n",
        "# Print out some descriptive statistics of our mesh cells\n",
        "print(domain.statistics())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The previous cell should print out some statistics of your mesh, as well as a picture of it. Note the \"Number of triangles\". How does this value change if you modify the `base_res` (mesh resolution)?\n",
        "\n",
        "After this cell, our model `domain` now exists, and we can begin populating it with information about our study site."
      ],
      "metadata": {
        "id": "jUTm_LARJjIC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO7vMG2Wehq1"
      },
      "source": [
        "## Create bathymetry/topography\n",
        "\n",
        "Now that we have a mesh, we need to provide **elevation** values for each of those cells. We do this using a **topographic DEM** stored in an ASCII file. This is the same DEM used in Lab 3, just converted into a different format and metric units. Because ANUGA requires DEMs to be stored in certain data-types, here we convert this data a couple times until it's in a format ANUGA can use (`.dem`, `.pts`). Finally, we use the resulting `.pts` file to create our model bathymetry.\n",
        "\n",
        "These steps can be **quite slow** for high-resolution meshes, so if the mesh isn't changing between runs, we recommend **saving the resulting topography** from the domain as a `.csv` and just re-loading that file for future runs. This file will be a long list of elevation values sorted by triangle ID.\n",
        "\n",
        "*Note: The ASCII file needs to have the same headers as the file used here, which sometimes isn't the default. To repeat these steps, check the ASCII file with a text editor and make sure it has the same headers as the example ASCII files in th ANUGA examples folder. It also needs the accompanying `.prj` file!*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lrg7kRj5eQHw"
      },
      "outputs": [],
      "source": [
        "# ASCII to DEM conversion\n",
        "anuga.asc2dem('ANUGA_OnionCreek_Tutorial/data/EG_OnionCreek_2m_EPSG_32614_m.asc',\n",
        "              use_cache=False, verbose=True)\n",
        "# DEM to \"points\"\n",
        "anuga.dem2pts('ANUGA_OnionCreek_Tutorial/data/EG_OnionCreek_2m_EPSG_32614_m.dem',\n",
        "              use_cache=False, verbose=True)\n",
        "# Use \"points\" to populate mesh cells\n",
        "domain.set_quantity('elevation', \n",
        "                    filename='ANUGA_OnionCreek_Tutorial/data/EG_OnionCreek_2m_EPSG_32614_m.pts',\n",
        "                    use_cache=False, verbose=True, alpha=0.1)\n",
        "\n",
        "# Plot topography\n",
        "fig=plt.figure(figsize=(5, 5), dpi= 250, facecolor='w', edgecolor='k')\n",
        "plt.tripcolor(dplotter.triang, facecolors = dplotter.elev, cmap = 'terrain')\n",
        "plt.colorbar(fraction=0.02);\n",
        "plt.title(\"Elevation\");\n",
        "plt.axis('scaled')\n",
        "\n",
        "# To save time next time, we can save the result\n",
        "# topo = domain.quantities['elevation'].centroid_values\n",
        "# np.savetxt('ANUGA_OnionCreek_Tutorial/data/EG_OnionCreek_2m_EPSG_32614_m.csv', topo, delimiter=\",\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXsbRZNaeqU-"
      },
      "source": [
        "## Add boundary conditions\n",
        "\n",
        "Now we use some nearby USGS gauge data to prescribe our model **boundary conditions**. Here we use two common types of BCs: **Dirichlet** and **Reflective**. For the former, we tell the model exactly what the water surface elevation and/or velocities are along that boundary as a function of time. For the latter, the boundary acts like a solid wall, bouncing any flows back inside the domain. \n",
        "\n",
        "We assign our downstream boundary condition to match the water surface elevations of the nearby gauge using ANUGA's `Time_boundary` function. ANUGA has **three conserved quantities** that we have to specify: [`stage`, `xmomentum`, `ymomentum`]. `stage` is the water surface elevation ($\\eta = z + h$), and `momentum` $q = [uh, vh]$. We use the gauge data to specify these along the downstream BC as a function of time (only `stage` is set to vary here). All the other boundaries are designated as a no-flux `Reflective_boundary`, because we don't expect flows in those directions.\n",
        "\n",
        "*Note: Due to **poor boundary placement** in relation to where these gauges are located, we've added a few fudge factors in the following sections for the purposes of this demonstration. Ideally, your boundaries should be drawn where you have a good sense for the **mass balance** of your system!*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KCZ5ob0eQLq"
      },
      "outputs": [],
      "source": [
        "# Load gauge data into a Pandas \"DataFrame\"\n",
        "usgs_a = pd.read_csv('ANUGA_OnionCreek_Tutorial/data/USGS_Onion183_metric.csv',\n",
        "                     header=0, names=['ID','datetime','tz','Q','WL'])\n",
        "usgs_a['datetime'] = pd.to_datetime(usgs_a['datetime']) # Convert to datetime dtype\n",
        "# Need to convert datetimes into 'seconds from initial time'\n",
        "usgs_a['epoch'] = (usgs_a['datetime'] - usgs_a['datetime'][0]) // pd.Timedelta(\"1s\")\n",
        "\n",
        "usgs_b = pd.read_csv('ANUGA_OnionCreek_Tutorial/data/USGS_Williamson_metric.csv',\n",
        "                     header=0, names=['ID','datetime','tz','Q','WL'])\n",
        "usgs_b['datetime'] = pd.to_datetime(usgs_b['datetime']) # Convert to datetime dtype\n",
        "# Need to convert datetimes into 'seconds from initial time'\n",
        "usgs_b['epoch'] = (usgs_b['datetime'] - usgs_b['datetime'][0]) // pd.Timedelta(\"1s\")\n",
        "\n",
        "# Print out one of these DataFrames to get a sense for what it looks like:\n",
        "usgs_a # This will print out a snippet. Looks like a spreadsheet!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have loaded in the data from two USGS gauges. Gauge \"A\" is [08159000 on Onion Creek at 183](https://waterdata.usgs.gov/nwis/uv/?site_no=08159000&agency_cd=USGS) and gauge B is [08158970 on Williamson Creek](https://waterdata.usgs.gov/nwis/uv/?site_no=08158970&agency_cd=USGS). Technically Gauge A is in the middle of our domain, but for this demonstration we're going to use it to define an inflow.\n",
        "\n",
        "The two datasets correspond to the storm that came through on March 21st 2022, which is the time period we're going to be modeling. The downloaded files span from 5PM on March 21st through March 24th, and all values have been converted to $[m]$ or $[m^3/s]$\n",
        "\n",
        "Let's use the water level information from Gauge A to specify the `stage` for our downstream boundary, by creating a function that interpolates this `DataFrame` as a function of time:"
      ],
      "metadata": {
        "id": "uvk0-leQNwKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vert_offset = 1.0 # Fudge factor, vertical correction to gauge data\n",
        "# Create a linear interpolation function for the WSE:\n",
        "fBC_downstream = interp1d(usgs_a['epoch'], usgs_a['WL'] + vert_offset, kind='linear')\n",
        "\n",
        "# Downstream boundary\n",
        "Bout = anuga.Time_boundary(domain, function=lambda t: [fBC_downstream(t), 0.0, 0.0])\n",
        "\n",
        "# All other boundaries\n",
        "Br = anuga.Reflective_boundary(domain)\n",
        "\n",
        "# Assign BCs to the boundaries we named earlier\n",
        "domain.set_boundary({'downstream': Bout, 'sides': Br})"
      ],
      "metadata": {
        "id": "4BH743Bu6gDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_9iZp41e0FX"
      },
      "source": [
        "## Add discharge hydrograph\n",
        "\n",
        "Now we add inflows of **discharge** from each of the two upstream channels. We do this by creating an **inlet** through which that discharge is added to the model.\n",
        "\n",
        "The way ANUGA handles discharge is somewhat odd compared to other models. Most models define a mass inflow as a boundary condition, and every time-step mass is added appropriately. Due to some weird quirks about how ANUGA's numerical solver handles BCs, it works better to add an **inlet** *inside the domain* through which water flows into our domain, somewhat like a flooding bath drain. (Note that **outlets** can be created the same way by specifying a **negative discharge**)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two more linear interpolation functions for Q\n",
        "# Fudge factor, changing timing & magnitude of gauge A to make up for poor BC placement\n",
        "usgs_a['epoch_2'] = (usgs_a['datetime'] - usgs_a['datetime'][0] - pd.Timedelta('70 min')) // pd.Timedelta(\"1s\") # Moves up flood arrival by 70 min\n",
        "fQ_a = interp1d(usgs_a['epoch_2'], usgs_a['Q']*0.8, kind='linear') # Scales down Q by 20%\n",
        "fQ_b = interp1d(usgs_b['epoch'], usgs_b['Q'], kind='linear')\n",
        "\n",
        "# Setup inlets (supply coordinates + add \"Inlet_operator\")\n",
        "first_inlet = np.array([[622627.,3339957.],[622627.,3339982.]]).astype('double') # Coordinates of line\n",
        "first_inflow = Inlet_operator(domain, first_inlet, Q = fQ_a)\n",
        "\n",
        "second_inlet = np.array([[623031,3341074],[623035,3341085]]).astype('double') # Coordinates of line\n",
        "second_inflow = Inlet_operator(domain, second_inlet, Q = fQ_b)\n",
        "\n",
        "# Visualize time-varying Q\n",
        "tt = np.linspace(0., 86400, 1000) # Vector of time values for plotting\n",
        "Qplta = [fQ_a(ti) for ti in tt] # Vector of Q values for each tt\n",
        "Qpltb = [fQ_b(ti) for ti in tt] # Vector of Q values for each tt\n",
        "plt.figure(figsize=(6,3), dpi=150)\n",
        "plt.plot(tt/3600., Qplta, 'g-')\n",
        "plt.plot(tt/3600., Qpltb, 'b-')\n",
        "plt.xlabel('Time [hrs]')\n",
        "plt.ylabel('Discharge [$m^3/s$]')\n",
        "plt.legend(['Inlet A','Inlet B'])"
      ],
      "metadata": {
        "id": "54EPOVaL-RoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now our domain will have inflows when we run the code. The `Inlet_operator` that we used above is an optional add-on function that tells ANUGA, in plain language, \"*there is an inlet here with this amount of discharge*\". \"Operator\" is a generic term for lots of optional add-ons in ANUGA that can modify the model in some way. The location of our inlet is just a simple line, and all the cells that intersect that line will act as our inlet. "
      ],
      "metadata": {
        "id": "z7sJav2ASQGF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPzLDP13e893"
      },
      "source": [
        "## Add rainfall\n",
        "\n",
        "We can also add rainfall to our model, which adds water to all our model cells at some specified rate (mm/s) over a specified period of time. \n",
        "\n",
        "For this simulation, we've simplified the real hyetograph into two windows of rainfall, based on nearby City of Austin estimates. There were roughly two periods of rainfall on March 21st: window 1 was around 6PM, and window 2 was around midnight. About 3.2 inches (81.3 mm) fell in total."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Details for our simplified hyetograph\n",
        "window1 = [2700, 5400] # Seconds after model start time (5PM on March 21st)\n",
        "window2 = [23400, 28800]\n",
        "rain_rate_window1 = 0.006778 # mm/s\n",
        "rain_rate_window2 = 0.011667 # mm/s\n",
        "\n",
        "# Create a function that returns the rainfall rate as a function of time\n",
        "def rainfall(t):\n",
        "  if window1[0] <= t < window1[1]:\n",
        "    rate = rain_rate_window1\n",
        "  elif window2[0] <= t < window2[1]:\n",
        "    rate = rain_rate_window2\n",
        "  else:\n",
        "    rate = 0.\n",
        "  return rate\n",
        "\n",
        "# Append to forcing terms; this adds rain to our model domain\n",
        "R = anuga.Rainfall(domain, rate=rainfall)\n",
        "domain.forcing_terms.append(R)\n",
        "\n",
        "# Visualize time-varying R\n",
        "tt = np.linspace(0., 86400, 1000) # Vector of time values for plotting\n",
        "RR = [rainfall(ti) for ti in tt] # Vector of rainfall values for each tt\n",
        "plt.figure(figsize=(6,3), dpi=150)\n",
        "plt.plot(tt/3600., RR, 'k-')\n",
        "plt.xlabel('Time [hrs]')\n",
        "plt.ylabel('Rainfall rate [$mm/s$]')"
      ],
      "metadata": {
        "id": "NAmqDafocBgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMVUFey5fGdH"
      },
      "source": [
        "## Initialize Stage\n",
        "\n",
        "Now we tie up a few loose ends. We need to specify the **stage** initial condition, which we set to equal the height at the downstream boundary anywhere where the elevation is lower than that value (and dry everywhere else). We can do this using `set_quantity()`, which we could have used to initialize any of our variables if we wanted to (e.g. momentum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dahibEFpfHgS"
      },
      "outputs": [],
      "source": [
        "# ---------------Load pre-established elevation----------------------\n",
        "topo = domain.quantities['elevation'].centroid_values\n",
        "stage = topo.copy()  # Initialize stage as = topography\n",
        "# Is elevation is lower than WSE downstream, set stage = WSE\n",
        "stage[topo <= fBC_downstream(0)] = fBC_downstream(0)\n",
        "domain.set_quantity('stage', stage, location='centroids')  # Initialize depth"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Friction\n",
        "\n",
        "Finally, we apply a uniform Manning's coefficient $n=0.05$ everywhere in the domain. Note that this value can vary spatially, we're just using one value for simplicity."
      ],
      "metadata": {
        "id": "eoXPkV8cW0pa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create empty vector of 1's with the same dimensions as topo, multiply by n\n",
        "friction = np.ones_like(topo)*0.05\n",
        "domain.set_quantity('friction', friction, location = 'centroids')"
      ],
      "metadata": {
        "id": "opgltpV8W04Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYmCPPVHfNTA"
      },
      "source": [
        "## Run the model\n",
        "\n",
        "Finally, we can run the model!\n",
        "\n",
        "Here we call on `domain.evolve()` to **run the model** for a specified amount of time. There are two kinds of timesteps to be aware of: the **model timestep** and the **yieldstep**. In ANUGA, the model timestep is automatically computed based on numerical stability conditions, and is usually some small value $\\approx \\mathcal{O}(1s)$. However, we can't save the data for every timestep, because output file would be enormous. We therefore specify a yieldstep, which is the time interval (in seconds) at which the model **saves information** on the model's converved quantities (`stage`, `xmomentum`, `ymomentum`) into the output file. We use the command `domain.print_timestepping_statistics()` to tell us some summary statistics of these timesteps every `yieldstep`.\n",
        "\n",
        "As the model runs, output data are saved into a NetCDF file with the extension `.sww`. This is a common and efficient data type for storing numeric data, and can be opened by many programs, not just ANUGA. \n",
        "\n",
        "The `domain.evolve()` function works like a typical *for* loop: *for t less than final time, evolve the model*. This enables us to **make changes to our model** as time progresses, if we wish. In this example, all of our BCs were defined as functions of time, so they are automatically updated each time step, but they also could have been defined as static values and then updated inside this loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdMOaHKyfHjK"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# Evolve system through time\n",
        "# ------------------------------------------------------------------------------\n",
        "savefreq = 900. # Yieldstep, in seconds\n",
        "simtime = 86400. # Total simulation time, in seconds\n",
        "\n",
        "for n, t in enumerate(domain.evolve(yieldstep=savefreq, finaltime=simtime)):\n",
        "    # Print out some statistics on the model evolution\n",
        "    domain.print_timestepping_statistics()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the model evolves, you should see timestepping statistics printed out every yieldstep. Here's the meaning for those numbers:\n",
        "- The first value is the \"real\" amount of time that has been modeled so far.\n",
        "- \"delta t\" is the range of model timesteps taken during that yieldstep.\n",
        "- \"steps\" is the number of model timesteps taken in that yieldstep.\n",
        "- The number in the parentheses at the end is the amount of clock time that has elapsed since the last yieldstep, i.e. how long you'll have to wait for the model to finish."
      ],
      "metadata": {
        "id": "Glu5KN1laTMi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnzPMUl_fVbY"
      },
      "source": [
        "## Inspect outputs\n",
        "\n",
        "Now that we've run the model, let's view some results!\n",
        "\n",
        "There is also a pre-saved output file in the GitHub folder, which you can use if you don't want to wait for your run to finish.\n",
        "\n",
        "There are a couple ways one can query the output file. ANUGA's `.sww` files can be loaded using any normal NetCDF reader, but ANUGA also comes pre-packaged with several functions for inspecting your model results, most of which are stored in `anuga.utilities.plot_utils`.\n",
        "\n",
        "First, load in the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbP7bZg9fZaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0707965-3785-4588-ce4d-0d2070573312"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure files for each frame will be stored in _plot\n"
          ]
        }
      ],
      "source": [
        "# Uncomment whichever one we're visualizing:\n",
        "saved_output = 'domain.sww' # Output of current run\n",
        "# saved_output = 'ANUGA_OnionCreek_Tutorial/notebooks/domain.sww' # Pre-saved output\n",
        "\n",
        "# Load in values of conserved quantities at every cell centroid\n",
        "swwvals = anuga.utilities.plot_utils.get_centroids(saved_output, timeSlices='all')\n",
        "# Query values: time, x, y, stage, elev, height, xmom, ymom, xvel, yvel, friction, vel, etc\n",
        "model_starttime = pd.to_datetime('2022-03-21 17:00:00')\n",
        "dplotter = animate.SWW_plotter(saved_output) # Update dplotter if necessary\n",
        "\n",
        "# Separate variables just for accessibility\n",
        "time = swwvals.time\n",
        "topo = swwvals.elev\n",
        "x = swwvals.x\n",
        "y = swwvals.y\n",
        "depth = swwvals.height\n",
        "stage = swwvals.stage\n",
        "u = swwvals.xvel\n",
        "v = swwvals.yvel\n",
        "w = np.sqrt(u**2 + v**2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make plotting functions\n",
        "\n",
        "To clean up the code, let's wrap some of these plotting codes into functions. Run the hidden block below, and feel free to open it if you want to see the details."
      ],
      "metadata": {
        "id": "ccJyE8zzyMe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_velocity(time_idx):\n",
        "  '''Makes figure of flow velocity at some time index'''\n",
        "  timeCDT = pd.to_timedelta(time[time_idx], 's') + model_starttime # Find time\n",
        "  fig = plt.figure(figsize=(5, 5), dpi=250, facecolor='w', edgecolor='k')\n",
        "  plt.tripcolor(dplotter.triang, facecolors=w[time_idx,:], \n",
        "                vmax=0.3, vmin=0, cmap='plasma') # Plot velocities\n",
        "  cbar = plt.colorbar(fraction=0.02); # Add colorbar\n",
        "  cbar.set_label('Velocity [m/s]', rotation=270, labelpad=10)\n",
        "  plt.title('Velocity : '+timeCDT.strftime(\"%b %d %Y, %H:%M\"));\n",
        "  plt.axis('scaled') # Scale axes\n",
        "  return\n",
        "\n",
        "def show_quiver(time_idx):\n",
        "  '''Makes quiver plot of flow velocity at some time index'''\n",
        "  timeCDT = pd.to_timedelta(time[time_idx], 's') + model_starttime # Find time\n",
        "  # Indices of where water is located:\n",
        "  inds = (w[time_idx,:] > 0.05) & (depth[time_idx,:] > 0.01)\n",
        "  inds[0::2] = 0  # Cut it down to half as many arrows\n",
        "  fig = plt.figure(figsize=(8, 8), dpi=300, facecolor='w', edgecolor='k')\n",
        "  # Show topography as the background:\n",
        "  plt.tripcolor(dplotter.triang, facecolors=dplotter.elev, cmap='Greys_r')\n",
        "  plt.colorbar(fraction=0.01);\n",
        "  plt.title(\"Flow Direction : \"+timeCDT.strftime(\"%b %d %Y, %H:%M\"));\n",
        "  # Create the quivers:\n",
        "  Quiv = plt.quiver(x[inds], y[inds], u[time_idx,inds], v[time_idx,inds],\n",
        "                    color='red', scale=30, width=0.001, headwidth=4, pivot='mid')\n",
        "  qk = plt.quiverkey(Quiv, 0.18, 0.66, 1, r'$1 \\frac{m}{s}$', labelpos='W',\n",
        "                    coordinates='figure', labelcolor='red') # Add a key\n",
        "  plt.axis('scaled') # Scale axis\n",
        "  return\n",
        "\n",
        "def show_inundation(time_idx):\n",
        "  '''Makes figure of flow depth at some time index'''\n",
        "  timeCDT = pd.to_timedelta(time[time_idx], 's') + model_starttime # Find time\n",
        "  fig = plt.figure(figsize=(5, 5), dpi=250, facecolor='w', edgecolor='k')\n",
        "  # Show topography as the background:\n",
        "  plt.tripcolor(dplotter.triang, facecolors=topo, cmap='Greys_r')\n",
        "  # We need to copy the variable so we can mask-out shallow cells:\n",
        "  plot_depth = depth[time_idx,:].copy()\n",
        "  plot_depth[plot_depth < 0.01] = np.nan\n",
        "  plt.tripcolor(dplotter.triang, facecolors=np.log10(plot_depth),\n",
        "                vmin=-2, vmax=1, cmap='Blues') # Plot depths\n",
        "  cbar = plt.colorbar(fraction=0.02) # Add colorbar\n",
        "  cbar.set_label('log10(Depth) [m]', rotation=270, labelpad=10)\n",
        "  plt.title('Depth : '+timeCDT.strftime(\"%b %d %Y, %H:%M\"));\n",
        "  plt.axis('scaled') # Scale axis\n",
        "  return\n",
        "\n",
        "def show_max_inundation():\n",
        "  '''Makes a figure of maximum inundation'''\n",
        "  fig = plt.figure(figsize=(5, 5), dpi=250, facecolor='w', edgecolor='k')\n",
        "  # Show topography as the background:\n",
        "  plt.tripcolor(dplotter.triang, facecolors=topo, cmap='Greys_r')\n",
        "  # We need to copy the variable so we can mask-out shallow cells:\n",
        "  plot_depth = np.nanmax(depth, axis=0) # Find max\n",
        "  plot_depth[plot_depth < 0.01] = np.nan\n",
        "  plt.tripcolor(dplotter.triang, facecolors=np.log10(plot_depth),\n",
        "                vmin=-2, vmax=1, cmap='Blues') # Plot depths\n",
        "  cbar = plt.colorbar(fraction=0.02) # Add colorbar\n",
        "  cbar.set_label('log10(Max Depth) [m]', rotation=270, labelpad=10)\n",
        "  plt.title('Maximum Depth');\n",
        "  plt.axis('scaled') # Scale axis\n",
        "  return"
      ],
      "metadata": {
        "id": "iliPQ4Z_yLWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flow Velocity\n",
        "\n",
        "One of the strengths of 2D modeling is getting to see the spatial patterns of flow in our landscape. Let's visualize the flow velocity at some particular time.\n",
        "\n",
        "Change `time_idx` to view the flow field at different times."
      ],
      "metadata": {
        "id": "qwKNQPaspDif"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmCuXAqifZcu"
      },
      "outputs": [],
      "source": [
        "# Time index to plot:\n",
        "time_idx = 32 # integer from 0-94\n",
        "\n",
        "# Make the figure\n",
        "show_velocity(time_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also visualize these velocities using a \"quiver map\", with arrows showing the direction of flow.\n",
        "\n",
        "Because there are a lot of arrows, we use the variable `inds` below to only show arrows in relevant cells."
      ],
      "metadata": {
        "id": "PcADqq-Np59_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Time index to plot:\n",
        "time_idx = 32\n",
        "\n",
        "# Make the figure\n",
        "show_quiver(time_idx)"
      ],
      "metadata": {
        "id": "GRrZm9ARpUc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inundation\n",
        "\n",
        "We can also visualize the flow depth, which is useful for monitoring flooding. In the cells below, we filter out depths $< 1cm$ to show flooding more clearly. We also plot the color-axis on a log-scale so you can more easily see spatial differences (the range $[-2, 1] = [1cm, 10m]$). "
      ],
      "metadata": {
        "id": "ixpfHTKkq350"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rGWBIHafj-q"
      },
      "outputs": [],
      "source": [
        "# Time index to plot:\n",
        "time_idx = 35\n",
        "\n",
        "# Make the figure\n",
        "show_inundation(time_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also plot the maximum inundation experienced by each cell:"
      ],
      "metadata": {
        "id": "h1Vn7yFgtZ3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the figure\n",
        "show_max_inundation()"
      ],
      "metadata": {
        "id": "Uf8QwKo_oGij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Gauge\n",
        "\n",
        "We can also extract time-series information at a point, which can be useful if we have gauges inside our domain to compare to. Let's pull out the time-series of water surface elevations near our Gauge A's true location.\n",
        "\n",
        "If this model is performing well, this should look similar to the water levels measured at that gauge. Let's plot both together and compare them."
      ],
      "metadata": {
        "id": "kIDuOIvDtsl7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7TeaxnlfkBV"
      },
      "outputs": [],
      "source": [
        "# Create triangle lookup function to find cell index of a gauge\n",
        "p = anuga.utilities.plot_utils.get_output(saved_output)\n",
        "tri_lookup = anuga.utilities.plot_utils.get_triangle_lookup_function(p)\n",
        "\n",
        "# Create time vector of model outputs\n",
        "model_timeseries = model_starttime + pd.to_timedelta(time, 's')\n",
        "\n",
        "# Find coordinates of gauge and cell containing it, extract stage\n",
        "xx, yy = [626300, 3339250]\n",
        "idx = tri_lookup(xx, yy)\n",
        "gaugestage = stage[:, idx]\n",
        "\n",
        "# Create figure:\n",
        "fig = plt.figure(figsize=(8, 4), dpi=150, facecolor='w', edgecolor='k')\n",
        "plt.plot(model_timeseries, gaugestage, 'r--') # Plot modeled gauge\n",
        "# Grab gauge stage from our downstream BC function\n",
        "tt = np.linspace(0., 86400, 1000) # Vector of seconds values\n",
        "gauge = [fBC_downstream(ti) for ti in tt] # Vector of WL values for each tt\n",
        "gauge_timeseries = model_starttime + pd.to_timedelta(tt, 's') # Convert to time\n",
        "plt.plot(gauge_timeseries, gauge, 'k-') # Plot gauge\n",
        "plt.ylabel('Stage [m]')\n",
        "plt.legend(['Modeled Stage','Gauge Stage'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fit could be better. If we wanted to try to improve it, our main options would probably be to: \n",
        "1. Change friction coefficients\n",
        "2. Increase our mesh resolution\n",
        "3. Move our model boundaries to better locations\n",
        "4. Check our input data to make sure there aren't any errors (e.g. mis-matching datums)\n",
        "\n",
        "\n",
        "## Plot Animation\n",
        "\n",
        "Finally, instead of viewing snapshots of time, we could also use some of the functions above to make animations for the whole simulation. Let's re-run one of those functions, but this time, let's loop through all values of `time_idx`, save each output, and turn them into an animation."
      ],
      "metadata": {
        "id": "m-4oGH2DxG-z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lk0AWFIeQT2"
      },
      "outputs": [],
      "source": [
        "for time_idx in range(0,len(time)):\n",
        "  # Make the figure for this time\n",
        "  show_velocity(time_idx)\n",
        "  # Save the figure and close it\n",
        "  plt.savefig('figure_%s.jpg' % time_idx)\n",
        "  plt.close()\n",
        "\n",
        "# Grab the list of files, and make sure they're in order\n",
        "files = glob.glob('figure_*.jpg')\n",
        "files = sorted(files, key=os.path.getmtime)\n",
        "outfile = 'animation.gif'\n",
        "\n",
        "# Create GIF\n",
        "imgs = [Image.open(f).copy() for f in files]\n",
        "imgs[0].save(fp=outfile, format='GIF', append_images=imgs[1:],\n",
        "              save_all=True, duration=200, loop=0) # Write gif"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the above code has been run, you can view the animation by opening the file manager on the left-hand side panel (looks like a folder) and double-clicking the `animation.gif`. This should open the file in a right-hand side panel. \n",
        "\n",
        "**Bonus**: Change out the `show_velocity` function used inside the loop for one of the other functions, `show_quiver` or `show_inundation`, to make a different animation."
      ],
      "metadata": {
        "id": "YO8jRptK0iTr"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ccJyE8zzyMe-"
      ],
      "name": "Delta-X Workshop - ANUGA",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}